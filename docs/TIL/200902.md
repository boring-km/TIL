# 0902 TIL
> **5장 스트림 코딩**
> - 5.1 스트림의 중요성
> - 5.2 스트림 시작하기

## 5.1 스트림의 중요성
- Node.js의 가장 중요한 컴포넌트?이며 패턴 중 하나이다.
- 성능이나 효율성과 같은 기술적 송성에 관한 것뿐만 아니라 그 세련됨과 Node.js 철학에 완벽하게 부합하는 방식이다.

### 5.1.1 버퍼링 대 스트리밍
- 버퍼(buffer) 모드: 리소스로부터 오는 모든 데이터를 버퍼에 수집한다. 그리고 자원을 모두 읽어들인 후 콜백에 전달한다.
- 스트림은 모든 데이터가 버퍼에 수집될 때까지 기다리지 않고 즉시 처리할 수 있다.

### 5.1.2 공간 효율성
- 버퍼링을 통해 모든 데이터를 한꺼번에 처리하는 방식으로는 불가능한 작업을 처리할 수 있다.
- V8 버퍼는 0x3FFFFFFF바이트보다 클 수 없다.(1GB보다 조금 작다고 함)
```javascript
// 버퍼링된 API를 사용한 Gzipping(압축)
const fs = require('fs');
const zlib = require('zlib');
const file = process.argv[2];

fs.readFile(file, (err, buffer) => {
    zlib.gzip(buffer, (err, buffer) => {
        fs.writeFile(file + '.gz', buffer, err => {
            console.log('File successfully compressed');
        });
    });
});

// 스트림을 사용한 Gzipping
const fs = require('fs');
const zlib = require('zlib');
const file = process.argv[2];

fs.createReadStream(file)
    .pipe(zlib.createGzip())
    .pipe(fs.createWriteStream(file + '.gz'))
    .on('finish', () => console.log('File successfully compressed'));
```
- 스트림을 이용해서 더 깨끗하고 우아하며 간결한 코드의 작성이 가능해진다.
- 1GB를 초과하는 큰 파일로 작업이 가능하다.

### 5.1.3 시간 효율성
- 예제: 파일을 압축하고 원격의 HTTP 서버에 업로드
- 버퍼링 API
  - 전체 파일을 읽어 압축한 경우에만 업로드 시작이 가능하다.
  - 압축 해제는 모든 데이터가 서버에 수신된 경우에만 시작 가능하다.
- 스트림
  - 파일 시스템에서 데이터 덩어리를 읽는 즉시 압축하고 보낼 수 있다.
  - 서버에서는 원격 피어(peer)에서 수신된 즉시 모든 덩어리를 압축 해제할 수 있다.

```javascript
// gzipResolve.js
const http = require('http');
const fs = require('fs');
const zlib = require('zlib');

const server = http.createServer((req, res) => {
    const filename = req.headers.filename;
    console.log('File request received: ' + filename);
    req.pipe(zlib.createGunzip())
        .pipe(fs.createWriteStream(filename))   // 스트림을 통해 네트워크에서 데이터 덩어리를 수신하고 압축을 풀어 저장한다.
        .on('finish', () => {
            res.writeHead(201, {'Content-Type': 'text/plain'});
            res.end(`That's it\n`);
            console.log(`File saved: ${filename}`);
        });
});
server.listen(3000, () => console.log('Listening'));

// gzipSend.js
const http = require('http');
const fs = require('fs');
const zlib = require('zlib');
const path = require('path');
const file = process.argv[2];
const server = process.argv[3];

const options = {
    hostname: server,
    port: 3000,
    path: '/',
    method: 'PUT',
    headers: {
        filename: path.basename(file)0,
        'Content-Type': 'application/octet-stream',
        'Content-Encoding': 'gzip'
    }
};

const req = http.request(options, res => {
    console.log('Server response: ' + res.statusCode);
});

fs.createReadStream(file)
    .pipe(zlib.createGzip())    // 파일 시스템에서 읽기 시작하면서
    .pipe(req)  // 바로 데이터를 보낸다.
    .on('finish', () => {
        console.log('File successfully sent');
    });
```
- 스트림이 전체 파일을 읽을 때까지 기다리지 않고 첫 번째 데이터 덩어리를 수신하자마자 조립 라인이 시작된다.
- 대신 조립 라인이 병렬로 실행된다.
- 실행하는 각 작업이 비동기적이면서 Node.js에 의해 병렬로 실행될 수 있기 때문에 완벽하게 작동한다.
- 유일한 제약은 데이터 덩어리가 각 단계에 도착하는 순서가 보존되어야 하는데 스트림이 이를 대신한다.
- **모든 데이터를 한꺼번에 읽고 처리하기 위해 시간을 낭비하지 않으므로 전체 프로세스의 시간이 단축된다.**

### 5.1.4 결합성
- 파이프라인의 다음 스트림이 이전 스트림에 의해 생성되어 전달된 데이터 타입을 지원해야 한다.
- pipe()를 사용하여 Node.js 스타일로 단일 기능을 담당하는 서로 다른 프로세스 유닛들을 연결한다.
```javascript
// 암호화 추가, 클라이언트에서 암호화
const crypto = require('crypto');
// ...
fs.createReadStream(file)
    .pipe(zlib.createGzip())
    .pipe(crypto.createCipher('aes192', 'a_shared_secret'))
    .pipe(req)
    .on('finish', () => console.log('File successfully sent'));

// 복호화 추가, 서버에서 복호화
const crypto = require('crypto');
// ...
const server = http.createServer((req, res) => {
    // ...
    req.pipe(crypto.createDecipher('aes192', 'a_shared_secret'))
        .pipe(zlib.createGunzip())
        .pipe(fs.createWriteStream(filename))
        .on('finish', () => {/* ... */});
});
```
- 이미 존재하는 파이프라인에 변환 스트림을 끼어 넣어 스트림을 재사용할 수 있다는 것을 확인함
- 스트림을 이용해 순수한 I/O를 다루는 것뿐만 아니라 코드를 단순화하고 모듈화하는 수단으로 사용한다.

## 5.2 스트림 시작하기


### 5.2.1 스트림의 구조
- Node.js의 스트림 코어 모듈에서 사용할 수 있는 4가지 추상 클래스
  - stream.Readable
  - stream.Writable
  - stream.Duplex
  - stream.Transform
- 각 스트림 클래스는 EventEmitter의 인스턴스이다.
- 항상 모든 스트림에 대한 오류 이벤트 수신기를 등록하는 것이 좋다.
- 스트림은 거의 모든 JavaScript의 값을 처리할 수 있다.

### 5.2.2 Readable 스트림
- 데이터 소스를 나타낸다.
- 수신 방법: non-flowing, flowing
- 스트림 읽기의 기본 패턴은 읽을 준비가 되었다는 신호인 'listener를 등록하는 것'이다.
#### non-flowing 모드
- 읽는 방법: readable 이벤트에 대하여 listener를 등록하고 다음 루프에서 내부의 버퍼가 비워질 때까지 모든 데이터를 읽는다.
- 내부 버퍼에서 동기식으로 데이터 덩어리(chunk)를 읽고 Buffer 또는 String 객체를 반환하는 read()를 사용해 수행할 수 있다.
- **필요할 때 즉시 스트림으로부터 명시적으로 데이터를 가져올 수 있다.**
```javascript
// non-flowing 예제
process.stdin
    .on('readable', () => {
        let chunk;
        console.log('New data available');
        while((chunk = process.stdin.read()) !== null) {
            console.log(
                `Chunk read: (${chunk.length}) "${chunk.toString()}"`
            );
        }
    })
    .on('end', () => process.stdout.write('End of stream'));
```
- read()는 Readable 스트림의 내부 버퍼에서 데이터를 읽어들이는 동기 작업이다.
- 스트림이 바이너리로 동작하고 있는 경우, 기본적으로 반환되는 데이터는 Buffer 객체이다.

#### Flowing 모드
- 읽는 방법: data 이벤트에 리스너를 등록한다.
- read()를 사용하여 꺼내지 않고 데이터가 도착하자마자 해당 리스너에 전달한다.
```javascript
// Stream1 버전
process.stdin
    .on('data', chunk => {
        console.log('New data available');
        console.log(
            `Chunk read: (${chunk.length}) "${chunk.toString()}"`
        );
    })
    .on('end', () => process.stdout.write('End of stream'));
```
#### Reader 스트림 구현하기
- stream.Readable의 prototype을 상속한 클래스를 만들어야함
- 임의의 문자열을 생성하는 스트림
```javascript
const stream = require('stream');
const Chance = require('chance');
const chance = new Chance();

class RandomStream extends stream.Readable {
    constructor(options) {
        super(options);
    }
    _read(size) {
        const chunk = chance.string();
        console.log(`Pushing chunk of size: ${chunk.lenth}`);
        this.push(chunk, 'utf8');
        if(chance.bool({liklihood: 5})) {
            this.push(null);
        }
    }
}

module.exports = RandomStream;
```
- read()는 스트림의 Consumer에 의해 호출되는 메서드이고, _read() 스트림의 서브 클래스에 의해 구현되며 직접 호출해서는 안된다.
- option 객체를 통해 전달할 수 있는 변수들
  - 버퍼를 문자열로 변환하는데 사용되는 encoding 변수(기본값은 null이다)
  - 객체 모드를 정하는 플래그(objectMode의 기본값은 false이다)
  - 내부 버퍼에 저장되는 데이터의 상한선, 이후 소스로부터 더 이상 데이터를 읽지 않는다.
- _read()
  - chance를 사용하여 임의의 문자열을 생성한다.
  - 생성된 문자열을 내부 읽기 버퍼에 푸시한다. String을 push하기 때문에 인코딩(utf8)을 지정한다.
  - 5%의 확률로 내부 버퍼에 EOF 상황(null)을 내부 버퍼에 푸시하여 스트림을 무작위적으로 종료시킨다.
- 동일한 호출 내에서 여러 번의 push가 있을 경우 push() 함수가 false를 반환하는지 확인해야한다.
  - 내부 버퍼가 highWatermark 제한에 도달 했기 때문에 데이터 추가를 중지하라는 의미이다.

```javascript
// generateRandom.js
const RandomStream = require('./randomStream');
const randomStream = new RandomStream();

randomStream.on('readable', () => {
    let chunk;
    while((chunk = randomStream.read()) !== null) {
        console.log(`Chunk received: ${chunk.toString()}`);
    }
});
```

### 5.2.3 Writable 스트림
- 데이터의 목적지를 나타낸다.

#### 스트림에 쓰기
```javascript
// 일부 데이터를 Writable 스트림으로 push
writable.write(chunk, [encoding], [callback])
```
- 인코딩은 선택, chunk가 String일 경우 지정 가능
- 콜백 함수도 선택, chunk가 하위 자원으로 flush되면 호출됨
- 스트림에 더이상 기록할 데이터가 없으면 end()
```javascript
writable.end([chunk], [encoding], [callback])
```
- end()를 이용해 마지막 데이터를 전달할 수 있다.
- 콜백 함수는 스트림에 쓴 모든 데이터가 하위 리소스로 flush 되었을 때 발생하는 finish 이벤트에 리스너를 등록하는 것과 같다.
```javascript
// entropyServer.js
const Chance = require('chance');
const chance = new Chance();

require('http').createServer((req, res) => {
    res.writeHead(200, {'Content-Type': 'text/plain'}); // 응답 헤더 작성
    while(chance.bool({likelihood: 95})) {  // 5% 확률로 종료되는 루프 시작
        res.write(chance.string() + '\n');  // 임의의 문자열을 스트림에 작성
    }
    res.end('\nThe end...\n');              // 루프가 끝나면 스트림에서 end() 호출
    res.on('finish', () => console.log('All data was sent'));       // finish 이벤트에 대한 리스너 등록, 모든 데이터가 하위 소켓에 flush될 때 발생한다.
}).listen(3000, () => console.log('Listening on http://localhost:3000'));
```
- res 객체: http.ServerResponse의 인스턴스이며 Writable 스트림이다

#### 백프레셔(Back-pressure)
- 스트림이 소비하는 것보다 더 빠르게 데이터를 쓸 경우 병목 현상 발생할 수 있음
- 해결 매커니즘은 들어오는 데이터를 버퍼링하는 것임
- 스트림이 writer에 피드백을 주지 않으면 내부 버퍼에 점점 더 많은 데이터가 축적되어 원치 않는 수준의 메모리 사용을 초래한다.
- 이를 피하기 위해 내부 버퍼가 highWatermark 제한(내부 버퍼의 크기 제한)을 초과하면 writable.write()는 false를 반환한다. -> 더 이상 데이터를 쓰지 말아야 함
- 버퍼가 비워지면 drain 이벤트가 발생하여 다시 쓰기 시작해도 좋다는 것을 알림

```javascript
const Chance = require('chance');
const chance = new Chance();
require('http').createServer((req, res) => {
    res.writeHead(200, {'Content-Type': 'text/plain'});

    function generateMore() {
        while(chance.bool({likelihood: 95})) {
            let shouldContinue = res.write(
                chance.string({length: (16 * 1024) - 1})    // 데이터 덩어리의 크기를 일부러 늘림
            );
            if(!shouldContinue) {   // res.write()의 리턴 값을 확인하여 false를 받으면 내부 버퍼가 가득 차서 더 이상 데이터를 쓸 수 없음을 의미
                console.log('Backpressure');
                return res.once('drain', generateMore);
            }
        }
        res.end('\nThe end...\n', () => console.log('All data was sent'));
    }
    generateMore();
}).listen(3000, () => console.log('Listening on http://localhost:3000'));
```

#### Writable 스트림 구현
- stream.Writable의 프로토타입을 상속받아 _write() 함수를 구현하여 새로운 Writable 스트림을 구현한다.
```json
{
    path: <path to a file>
    content: <string or buffer>
}
```
- path와 content 형식으로 **객체**를 받는 Writable 스트림
- 주어진 경로에 생성된 파일의 내용을 저장
```javascript
// toFileStream.js
const stream = require('stream');
const fs = require('fs');
const path = require('path');
const mkdirp = require('mkdirp');
class ToFileStream extends stream.Writable {
    constructor() {
        super({objectMode: true});
    }

    _write(chunk, encoding, callback) {
        mkdirp(path.dirname(chunk.path), err => {
            if(err) {
                return callback(err);
            }
            fs.writeFile(chunk.path, chunk.content, callback);
        });
    }
}
module.exports = ToFileStream;
```
- stream.Writable에서 사용할 수 있는 옵션: highWaterMark(기본값 16K), decodeStrings(기본값 true; 바이너리 버퍼 내 문자열 디코딩; object모드에서는 무시됨)
```javascript
// writeToFile.js
const ToFileStream = require('./toFileStream.js');
const tfs = new ToFileStream();

tfs.write({path: "file1.txt", content: "Hello"});
tfs.write({path: "file2.txt", content: "Node.js"});
tfs.write({path: "file3.txt", content: "Streams"});
tfs.end(() => console.log("All files created"));
```

### 5.2.4 양방향(Duplex) 스트림
- Readable, Writable 모두 가능한 스트림
- 소켓처럼 데이터 소스와 데이터 목적지를 모두 가지는 항목을 다룰 때 유용함
- 사용자 정의 이중 스트림을 생성하려면 _read() 및 _write() 메서드를 구현해야 함

### 5.2.5 Transform 스트림
- 데이터 변환을 처리하도록 설계된 특별한 종류의 이중 스트림
- 간단한 양방향 스트림에서는 스트림에서 읽은 데이터와 스트림에 쓰는 데이터 사이에 직접적인 관계가 없다.
- Transform 스트림은 Writable 쪽에서 받은 각 데이터들에 어떤 종류의 변형을 적용하여 Readable 쪽에서 사용할 수 있도록 한다. (write -> Transform 스트림 변환 -> read)
- 외부에서 볼 때는 Duplex 스트림과 인터페이스 동일함
- 새로운 Transform 스트림 구현 시 transform()과 _flush() 메서드를 추가 작성해 줘야 한다.

### 5.2.6 Transform 스트림 구현
- 주어진 모든 문자열을 대체하는 예제
```javascript
// replaceStream.js
const stream = require('stream');
const util = require('util');

class ReplaceStream extends stream.Transform {
    constructor(searchString, replaceString) {
        super();
        this.searchString = searchString;
        this.replaceString = replaceString;
        this.tailPiece = '';
    }

    _transform(chunk, encoding, callback) {
        const pieces = (this.tailPiece + chunk).split(this.searchString);
        const lastPiece = pieces[pieces.length - 1];
        const tailPieceLen = this.searchString.length - 1;

        this.tailPiece = lastPiece.slice(-tailPieceLen);
        pieces[pieces.length - 1] = lastPiece.slice(0, -tailPieceLen);

        this.push(pieces.join(this.replaceString)); // 내부 버퍼로 push
        callback();
    }

    _flush(callback) {
        this.push(this.tailPiece);
        callback();
    }
}
module.exports = ReplaceStream;
```
- 데이터가 스트리밍 될 때에는 치환 가능한 검색 항목이 여러 데이터 덩어리(chunk)에 분산되어 있을 수 있다.
- (직접 실습해보기!)